{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our common data handling package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import gc\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#remove any of the titles\n",
    "episode=pd.read_csv('../data/episode_info.csv')\n",
    "listofepisodetitles=[str(s).lower().replace(' ','') for s in episode.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the main characters\n",
    "Monica=[]\n",
    "Ross=[]\n",
    "Phoebe=[]\n",
    "Joey=[]\n",
    "Rachel=[]\n",
    "Chandler=[]\n",
    "All=[]\n",
    "scenes=[]\n",
    "minors=[]\n",
    "all_char=[['monica', True],['ross', True],['phoebe', True],['joey', True],['rachel', True],['chandler', True]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for all the seasons in the set [from_season, to_season]\n",
    "\n",
    "from_season=1\n",
    "to_season=10\n",
    "\n",
    "\n",
    "#almost the number of scripts per episode\n",
    "mumberofepisodes=[24, 24,25, 23, 23, 25, 23, 23, 24, 18]\n",
    "\n",
    "#A table where our information will go for now\n",
    "allwords=[]\n",
    "strings=\"https://brookeogrodnik.github.io/scripts/{}.html\"\n",
    "\n",
    "for seas in range(from_season,to_season+1):\n",
    "    for epi in range(1, mumberofepisodes[seas-1]+1):\n",
    "        search=True\n",
    "        val=100*seas+epi\n",
    "        \n",
    "        #not dealing with 1 script for 2 epsiodes here (and other places also, but only these changed the name of the file)\n",
    "        if val not in [212, 213, 615, 616, 624, 625, 923, 924, 1017, 1018]:\n",
    "        \n",
    "            if val<1000:\n",
    "                val='0'+str(val)\n",
    "            else:\n",
    "                val=str(val)\n",
    "                \n",
    "        #we already read these ones in \n",
    "        elif val in  [213, 616, 625,  924, 1018]:\n",
    "            search=False\n",
    "            \n",
    "        #special names \n",
    "        elif val==212:\n",
    "            val='0212-0213'\n",
    "        elif val==615:\n",
    "            val='0615-0616'    \n",
    "        elif val==624:\n",
    "            val='0624'\n",
    "        elif val==923:\n",
    "            val='0923-0924'\n",
    "        elif val==1017:\n",
    "            val='1017-1018'    \n",
    "        \n",
    "        if search:\n",
    "            html = urlopen(strings.format(val))\n",
    "            soup = BeautifulSoup(html,\"html.parser\")\n",
    "            theirHTMLisWeird=soup.find_all(text=True)\n",
    "            \n",
    "            allwords.append([[seas, epi], theirHTMLisWeird])\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets rid of a bunch of stuff we really don't want in the script\n",
    "def allowed(line_of_script):\n",
    "    l=str(line_of_script).lower().replace(\" \",\"\")\n",
    "    if l=='' or l=='.': return False\n",
    "    if l.find('commericalbreak')>-1: return False\n",
    "    if l=='openingcredits': return False\n",
    "    if l=='closingcredits': return False\n",
    "    if l=='\\n': return False\n",
    "    if l.find('<!--')>-1: return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more absolute junk in the begining \n",
    "def allowed_after_initial_clean(line_of_script):\n",
    "    l=str(line_of_script).lower().replace(\" \",\"\")\n",
    "    if l.find('note:')==0: return False\n",
    "    if l.find('writtenby')>-1: return False\n",
    "    if l.find('transcribedby')>-1: return False\n",
    "    if l.find('transcriptby')>-1: return False\n",
    "    if l.find('directedby')>-1: return False\n",
    "    if l.find('transcribingby')>-1: return False\n",
    "    if l.find('withminoradjustmentsby')>-1: return False\n",
    "    if l.find('withminotadjustmentsby')>-1: return False\n",
    "    if l.find('withhelpfrom:')>-1: return False\n",
    "    if l.find('guineapig')>-1: return False\n",
    "    if l.find('trascribedby')>-1: return False\n",
    "    if l.find('@')>-1: return False\n",
    "    if l.find('storyby:')>-1: return False\n",
    "    if l.find('story:')==0: return False\n",
    "    if l.find('aired:')==0: return False\n",
    "    if l.find('mindymattinglyphillips')>-1: return False\n",
    "    if l.find('dansilverstein')>-1: return False\n",
    "    if l.find('joshhodge')>-1: return False\n",
    "    if l.find('alexajunge')>-1: return False\n",
    "    if l.find('iraungerleider')>-1: return False\n",
    "    if l.find('brownmandell')>-1: return False\n",
    "    if l.find('joshuahodge')>-1: return False\n",
    "    if l.find('adamchase')>-1: return False\n",
    "    if l.find('???')==0: return False\n",
    "    if l.find('teleplayby')>-1: return False\n",
    "    if l.find('ericbaasen')>-1: return False\n",
    "    if l.find('html')>-1: return False\n",
    "    if l.find('aliciaskyvarinaitis')>-1: return False\n",
    "    if l.find('markj.kunerth')>-1: return False\n",
    "    if l.find('ruthcurran')>-1: return False\n",
    "    if l in listofepisodetitles: return False\n",
    "    if l.find('-theonewith')>-1: return False\n",
    "    if l.find('-theonein')>-1: return False\n",
    "    if l.find('-thelastone')>-1: return False\n",
    "    if l.find('-theoneafter')>-1: return False\n",
    "    if l.find('-theonewhere')>-1: return False\n",
    "    if l.find('914theonewith')==0: return False\n",
    "    if l.find('theonewith')==0: return False\n",
    "    if l.find('heonewith')==0: return False\n",
    "    if l.find('theoneafter')==0: return False\n",
    "    if l.find('theonethemorningafter')==0: return False\n",
    "    if l.find('theonewhere')==0: return False\n",
    "    if l.find('theoneinvegas')==0: return False\n",
    "    if l.find('theonethelastnight')==0: return False\n",
    "    if l.find('friends-')==0: return False\n",
    "    if l.find('teleplay')==0: return False\n",
    "    if l.find('transcriberâ€™snote')>-1: return False\n",
    "    if l.find('dutchphrasesby')>-1: return False\n",
    "    if l.find('url=')>-1: return False\n",
    "    if l.find('creationdate:')>-1: return False\n",
    "    if l.find('generatedby')==0: return False\n",
    "    if l.find('produced')==0: return False\n",
    "    if l.find('untitleddocument')==0: return False\n",
    "    if l.find('russiantoroman')==0: return False\n",
    "    if l.find('templatebegineditable')==0: return False\n",
    "    if l.find('templateendeditable')==0: return False\n",
    "    if l.find('finalcheckby')==0: return False\n",
    "    if l.find('bluetext')>-1: return False\n",
    "    if l==',': return False\n",
    "    if line_of_script=='Friends': return False\n",
    "    if l.find(\"transcriber's\")>-1: return False\n",
    "    \n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templist=[0]*len(allwords)\n",
    "\n",
    "#Trying to fix most of the inconsitencies\n",
    "for pos in range(0,len(allwords)):\n",
    "\n",
    "    \n",
    "    episode_info=allwords[pos][0]\n",
    "    \n",
    "    #get rid of blank lines and the \\n, change all parenthesis and other such \n",
    "    #groupings to backets then strip it so we have no white space on the outsides\n",
    "    script=[str(line).replace('\\n',' ').replace('\\xa0',' ').replace('<','[').replace('(','[').replace('>',']').replace(')',']').strip() for line in allwords[pos][1] if allowed(line)]\n",
    "    \n",
    "    \n",
    "    #one last runthrough to get rid of empty lines\n",
    "    script=[line for line in script if len(line)>0]\n",
    "    \n",
    "    \n",
    "    #combine the name and the begining of their script\n",
    "    newscript=[]\n",
    "    k=0\n",
    "    while k in range(0, len(script)):\n",
    "        current_word=script[k]\n",
    "        \n",
    "        if (current_word[len(current_word)-1]==':') or (k<len(script)-1 and script[k+1][0]==':'):\n",
    "            newscript.append(current_word+' '+script[k+1])\n",
    "            k=k+1\n",
    "        else:\n",
    "            newscript.append(current_word)\n",
    "        k=k+1\n",
    "\n",
    "\n",
    "    \n",
    "    #combine the [ ]\n",
    "    script=newscript\n",
    "    newscript=[]\n",
    "    k=0\n",
    "    while k in range(0, len(script)):\n",
    "        current_word=script[k]\n",
    "        brack=current_word.find('[')\n",
    "        if brack>-1 and current_word[brack+1:len(current_word)].find(']')<0:\n",
    "            hasnt_been_found=True\n",
    "            s=1\n",
    "            temp_word=current_word\n",
    "           \n",
    "            while hasnt_been_found and k+s<len(script):\n",
    "                temp_word=temp_word+' '+script[k+s]\n",
    "                if script[k+s].find(']')>-1:\n",
    "                    hasnt_been_found=False\n",
    "                else:\n",
    "                    s=s+1\n",
    "                \n",
    "            newscript.append(temp_word)\n",
    "            k=k+s\n",
    "        else:\n",
    "            newscript.append(current_word)\n",
    "        k=k+1\n",
    "\n",
    "    \n",
    "    #get rid of flashback comment if it is followed by a scene\n",
    "    script=newscript\n",
    "    newscript=[]\n",
    "    k=0\n",
    "    while k in range(0, len(script)):\n",
    "        if k<len(script)-1 and script[k].lower().replace(' ','').find('[flash')==0 and script[k+1].lower().replace(' ','').find('[scene')==0: pass\n",
    "        else: newscript.append(script[k])\n",
    "        k=k+1\n",
    "\n",
    "    \n",
    "    #making sure scene has its own line    \n",
    "    script=newscript\n",
    "    newscript=[]\n",
    "    k=0\n",
    "    while k in range(0, len(script)):\n",
    "        current_word=script[k].lower()\n",
    "        if current_word.replace(' ','').find('[scene')>-1 and current_word.replace(' ','').find('[scene')!=0:\n",
    "            positon=current_word.find('[scene')\n",
    "            if positon <0:\n",
    "                positon=current_word.find('[ scene')\n",
    "            if positon<0:\n",
    "                positon=current_word.find('scene')\n",
    "            newscript.append(current_word[0:positon])\n",
    "            newscript.append(current_word[positon:len(current_word)])\n",
    "        else:\n",
    "            newscript.append(current_word)\n",
    "        k=k+1\n",
    "            \n",
    "\n",
    "    \n",
    "    #fix more with the :\n",
    "    script=[line for line in newscript if allowed_after_initial_clean(line)]\n",
    "    newscript=[]\n",
    "    k=0\n",
    "    while k in range(0, len(script)):\n",
    "        current_word=script[k].lower()\n",
    "        while k<len(script)-1 and current_word.find(':')>-1 and script[k+1].lower().replace(' ','').find('[scene')<0 and (script[k+1].find(':')<0 or script[k+1].lower().find('sequence')>0) and script[k+1].lower()!='end' and script[k+1].lower()!='the end' and script[k+1].replace(' ','').lower()!='endingcredits':\n",
    "            current_word=current_word+' '+script[k+1]\n",
    "            k=k+1\n",
    "        newscript.append(current_word)\n",
    "        k=k+1    \n",
    "\n",
    "        \n",
    "     \n",
    "    \n",
    "    \n",
    "    templist[pos]=[episode_info, newscript]\n",
    "    \n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now have the new allwords\n",
    "allwords=templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking into account sometimes its scene, scene- or scene.\n",
    "def find_split(n1, n2, n3,n4):\n",
    "    if -1<n1<n2 and -1<n1<n3:\n",
    "        return n1\n",
    "    if -1<n2<n1 and -1<n2<n3:\n",
    "        return n2\n",
    "    if -1<n3<n1 and -1<n3<n2:\n",
    "        return n3\n",
    "    if -1<n1<n2:\n",
    "        return n1\n",
    "    if -1<n1<n3:\n",
    "        return n1\n",
    "    if -1<n2<n3:\n",
    "        return n2\n",
    "    if -1<n3<n2:\n",
    "        return n3\n",
    "    if -1<n1:\n",
    "        return n1\n",
    "    if -1<n2:\n",
    "        return n2\n",
    "    if -1<n3:\n",
    "        return n3\n",
    "\n",
    "    \n",
    "    return n4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#season 2 epsiode 7,8,10 abbreviated important names\n",
    "#also sometimes everyone or everybody was used in place of all\n",
    "def full_clean(text):\n",
    "    text=text.replace('mnca:','monica:')\n",
    "    text=text.replace('phoe:','phoebe:')\n",
    "    text=text.replace('rach:','rachel:')\n",
    "    text=text.replace('chan:','chandler:')\n",
    "    text=text.replace('estl:','estelle:')\n",
    "    \n",
    "    if text.find('everyone:')==0:\n",
    "        text='all: '+text[9:len(text)].strip()\n",
    "    if text.find('everybody:')==0:\n",
    "        text='all: '+text[10:len(text)].strip()\n",
    "    if text.find('everybody ')==0:\n",
    "        text='all '+text[10:len(text)].strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1]\n",
      "[1, 2]\n",
      "[1, 3]\n",
      "[1, 4]\n",
      "[1, 5]\n",
      "[1, 6]\n",
      "[1, 7]\n",
      "[1, 8]\n",
      "[1, 9]\n",
      "[1, 10]\n",
      "[1, 11]\n",
      "[1, 12]\n",
      "[1, 13]\n",
      "[1, 14]\n",
      "[1, 15]\n",
      "[1, 16]\n",
      "[1, 17]\n",
      "[1, 18]\n",
      "[1, 19]\n",
      "[1, 20]\n",
      "[1, 21]\n",
      "[1, 22]\n",
      "[1, 23]\n",
      "[1, 24]\n",
      "[2, 1]\n",
      "[2, 2]\n",
      "[2, 3]\n",
      "[2, 4]\n",
      "[2, 5]\n",
      "[2, 6]\n",
      "[2, 7]\n",
      "[2, 8]\n",
      "[2, 9]\n",
      "[2, 10]\n",
      "[2, 11]\n",
      "[2, 12]\n",
      "[2, 14]\n",
      "[2, 15]\n",
      "[2, 16]\n",
      "[2, 17]\n",
      "[2, 18]\n",
      "[2, 19]\n",
      "[2, 20]\n",
      "[2, 21]\n",
      "[2, 22]\n",
      "[2, 23]\n",
      "[2, 24]\n",
      "[3, 1]\n",
      "[3, 2]\n",
      "[3, 3]\n",
      "[3, 4]\n",
      "[3, 5]\n",
      "[3, 6]\n",
      "[3, 7]\n",
      "[3, 8]\n",
      "[3, 9]\n",
      "[3, 10]\n",
      "[3, 11]\n",
      "[3, 12]\n",
      "[3, 13]\n",
      "[3, 14]\n",
      "[3, 15]\n",
      "[3, 16]\n",
      "[3, 17]\n",
      "[3, 18]\n",
      "[3, 19]\n",
      "[3, 20]\n",
      "[3, 21]\n",
      "[3, 22]\n",
      "[3, 23]\n",
      "[3, 24]\n",
      "[3, 25]\n",
      "[4, 1]\n",
      "[4, 2]\n",
      "[4, 3]\n",
      "[4, 4]\n",
      "[4, 5]\n",
      "[4, 6]\n",
      "[4, 7]\n",
      "[4, 8]\n",
      "[4, 9]\n",
      "[4, 10]\n",
      "[4, 11]\n",
      "[4, 12]\n",
      "[4, 13]\n",
      "[4, 14]\n",
      "[4, 15]\n",
      "[4, 16]\n",
      "[4, 17]\n",
      "[4, 18]\n",
      "[4, 19]\n",
      "[4, 20]\n",
      "[4, 21]\n",
      "[4, 22]\n",
      "[4, 23]\n",
      "[5, 1]\n",
      "[5, 2]\n",
      "[5, 3]\n",
      "[5, 4]\n",
      "[5, 5]\n",
      "[5, 6]\n",
      "[5, 7]\n",
      "[5, 8]\n",
      "[5, 9]\n",
      "[5, 10]\n",
      "[5, 11]\n",
      "[5, 12]\n",
      "[5, 13]\n",
      "[5, 14]\n",
      "[5, 15]\n",
      "[5, 16]\n",
      "[5, 17]\n",
      "[5, 18]\n",
      "[5, 19]\n",
      "[5, 20]\n",
      "[5, 21]\n",
      "[5, 22]\n",
      "[5, 23]\n",
      "[6, 1]\n",
      "[6, 2]\n",
      "[6, 3]\n",
      "[6, 4]\n",
      "[6, 5]\n",
      "[6, 6]\n",
      "[6, 7]\n",
      "[6, 8]\n",
      "[6, 9]\n",
      "[6, 10]\n",
      "[6, 11]\n",
      "[6, 12]\n",
      "[6, 13]\n",
      "[6, 14]\n",
      "[6, 15]\n",
      "[6, 17]\n",
      "[6, 18]\n",
      "[6, 19]\n",
      "[6, 20]\n",
      "[6, 21]\n",
      "[6, 22]\n",
      "[6, 23]\n",
      "[6, 24]\n",
      "[7, 1]\n",
      "[7, 2]\n",
      "[7, 3]\n",
      "[7, 4]\n",
      "[7, 5]\n",
      "[7, 6]\n",
      "[7, 7]\n",
      "[7, 8]\n",
      "[7, 9]\n",
      "[7, 10]\n",
      "[7, 11]\n",
      "[7, 12]\n",
      "[7, 13]\n",
      "[7, 14]\n",
      "[7, 15]\n",
      "[7, 16]\n",
      "[7, 17]\n",
      "[7, 18]\n",
      "[7, 19]\n",
      "[7, 20]\n",
      "[7, 21]\n",
      "[7, 22]\n",
      "[7, 23]\n",
      "[8, 1]\n",
      "[8, 2]\n",
      "[8, 3]\n",
      "[8, 4]\n",
      "[8, 5]\n",
      "[8, 6]\n",
      "[8, 7]\n",
      "[8, 8]\n",
      "[8, 9]\n",
      "[8, 10]\n",
      "[8, 11]\n",
      "[8, 12]\n",
      "[8, 13]\n",
      "[8, 14]\n",
      "[8, 15]\n",
      "[8, 16]\n",
      "[8, 17]\n",
      "[8, 18]\n",
      "[8, 19]\n",
      "[8, 20]\n",
      "[8, 21]\n",
      "[8, 22]\n",
      "[8, 23]\n",
      "[9, 1]\n",
      "[9, 2]\n",
      "[9, 3]\n",
      "[9, 4]\n",
      "[9, 5]\n",
      "[9, 6]\n",
      "[9, 7]\n",
      "[9, 8]\n",
      "[9, 9]\n",
      "[9, 10]\n",
      "[9, 11]\n",
      "[9, 12]\n",
      "[9, 13]\n",
      "[9, 14]\n",
      "[9, 15]\n",
      "[9, 16]\n",
      "[9, 17]\n",
      "[9, 18]\n",
      "[9, 19]\n",
      "[9, 20]\n",
      "[9, 21]\n",
      "[9, 22]\n",
      "[9, 23]\n",
      "[10, 1]\n",
      "[10, 2]\n",
      "[10, 4]\n",
      "[10, 5]\n",
      "[10, 6]\n",
      "[10, 7]\n",
      "[10, 8]\n",
      "[10, 9]\n",
      "[10, 10]\n",
      "[10, 11]\n",
      "[10, 12]\n",
      "[10, 13]\n",
      "[10, 14]\n",
      "[10, 15]\n",
      "[10, 16]\n",
      "[10, 17]\n"
     ]
    }
   ],
   "source": [
    "unknown_junk=[]\n",
    "\n",
    "#if a specific script isn't working, change issue to its index so you get print statemenet along the way\n",
    "issue=-1\n",
    "\n",
    "#loop through the script we imported and start making some datasets\n",
    "for i in range(0, len(allwords)):\n",
    "\n",
    "  \n",
    "    season=allwords[i][0][0]\n",
    "    episode=allwords[i][0][1]\n",
    "    \n",
    "    #just so we know our progress\n",
    "    print([season, episode])\n",
    "    \n",
    "    scene_count=0\n",
    "    location=''\n",
    "    extra=''\n",
    "    order=0\n",
    "    \n",
    "    #start the loop at 0 and go until we are done\n",
    "    j=0\n",
    "    while j in range(0, len(allwords[i][1])):\n",
    "        gc.collect()\n",
    "        text=allwords[i][1][j].lower().strip()\n",
    "        clean_text=full_clean(text)\n",
    "        \n",
    "        if issue==episode: print(clean_text)\n",
    "        \n",
    "        #did we reach the end of the script\n",
    "        if clean_text=='ending credits' or clean_text=='end' or clean_text=='the end' or j==len(allwords[i][1])-1:\n",
    "            scenes.append([season, episode,scene_count, location, extra])\n",
    "            \n",
    "            \n",
    "        #we check if it is a knew scene\n",
    "        elif clean_text.replace(' ','').find('[scene')==0:\n",
    "            if scene_count!=0:\n",
    "                scenes.append([season, episode, scene_count, location, extra])\n",
    "           \n",
    "            #start figuring out what it is telling you about the scene\n",
    "            mini=clean_text.replace('[scene,','').replace('[scene;','').replace('[scene','').replace(']','').replace('[','').replace(':','').strip()\n",
    "            \n",
    "            if mini.find(',')>-1 and (mini[0:mini.find(',')]=='ross' or mini[0:mini.find(',')]=='monica' or  mini[0:mini.find(',')]=='chandler'):\n",
    "                location=\" \".join(mini.split())\n",
    "                extra=''\n",
    "            else:    \n",
    "                #does it go scene and then - or . or ,\n",
    "                split=int(find_split(mini.find(','), mini.find('.'), mini.find('-'),len(mini)))\n",
    "            \n",
    "           \n",
    "            \n",
    "                location=\" \".join(mini[0:split].split())\n",
    "            \n",
    "                if split<len(mini)-1:\n",
    "                    extra=\" \".join(mini[split+1:len(mini)].split())\n",
    "            \n",
    "            scene_count=scene_count+1\n",
    "            order=0\n",
    "            \n",
    "        #we check if it is a knew scene via a flashback to scene\n",
    "        elif clean_text.replace(' ','').find('[flashback')==0:\n",
    "            if scene_count!=0:\n",
    "                scenes.append([season, episode, scene_count, location, extra])\n",
    "           \n",
    "            #start figuring out what it is telling you about the scene\n",
    "            mini=clean_text.replace('[flashback','').replace(']','').replace('[','').replace(':','').replace('scene','').strip()\n",
    "            \n",
    "            #does it go scene and then - or . or ,\n",
    "            split=int(find_split(mini.find(','), mini.find('.'), mini.find('-'),len(mini)))\n",
    "            \n",
    "           \n",
    "            \n",
    "            location=\" \".join(mini[0:split].split())\n",
    "            \n",
    "            if split<len(mini)-1:\n",
    "                extra=\" \".join(mini[split+1:len(mini)].split())\n",
    "            \n",
    "            scene_count=scene_count+1\n",
    "            order=0\n",
    "            \n",
    "            \n",
    "        #its a monica line    \n",
    "        elif clean_text.replace(' ','').find('monica:')>-1:\n",
    "            edited_text=clean_text[7:len(clean_text)].replace(':',' ').strip()\n",
    "            split=''\n",
    "            \n",
    "            #find all comments and move them\n",
    "            while edited_text.find('[')>-1:\n",
    "                temp_string=edited_text[edited_text.find('['):edited_text.find(']')+1]\n",
    "                split=split+' '+temp_string\n",
    "                edited_text=edited_text[0:edited_text.find('[')]+' '+edited_text[edited_text.find(']')+1:len(edited_text)]\n",
    "            \n",
    "            Monica.append([season,episode, scene_count, order, \" \".join(edited_text.split()),  \" \".join(split.split())])\n",
    "            order=order+1\n",
    "            \n",
    "            \n",
    "        #its a ross line    \n",
    "        elif clean_text.replace(' ','').find('ross:')>-1:\n",
    "            edited_text=clean_text[5:len(clean_text)].replace(':',' ').strip()\n",
    "            split=''\n",
    "            \n",
    "            #find all comments and move them\n",
    "            while edited_text.find('[')>-1:\n",
    "                temp_string=edited_text[edited_text.find('['):edited_text.find(']')+1]\n",
    "                split=split+' '+temp_string\n",
    "                edited_text=edited_text[0:edited_text.find('[')]+' '+edited_text[edited_text.find(']')+1:len(edited_text)]\n",
    "            \n",
    "            Ross.append([season,episode, scene_count, order,\" \".join(edited_text.split()),  \" \".join(split.split())])\n",
    "            order=order+1\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "        #its a phoebe line    \n",
    "        elif clean_text.replace(' ','').find('phoebe:')>-1:\n",
    "            edited_text=clean_text[7:len(clean_text)].replace(':',' ').strip()\n",
    "            split=''\n",
    "            \n",
    "            #find all comments and move them\n",
    "            while edited_text.find('[')>-1:\n",
    "                temp_string=edited_text[edited_text.find('['):edited_text.find(']')+1]\n",
    "                split=split+' '+temp_string\n",
    "                edited_text=edited_text[0:edited_text.find('[')]+' '+edited_text[edited_text.find(']')+1:len(edited_text)]\n",
    "            \n",
    "            Phoebe.append([season,episode, scene_count, order, \" \".join(edited_text.split()),  \" \".join(split.split())])\n",
    "            order=order+1\n",
    "            \n",
    "            \n",
    "        #its a joey line    \n",
    "        elif clean_text.replace(' ','').find('joey:')>-1:\n",
    "            edited_text=clean_text[5:len(clean_text)].replace(':',' ').strip()\n",
    "            split=''\n",
    "            \n",
    "            #find all comments and move them\n",
    "            while edited_text.find('[')>-1:\n",
    "                temp_string=edited_text[edited_text.find('['):edited_text.find(']')+1]\n",
    "                split=split+' '+temp_string\n",
    "                edited_text=edited_text[0:edited_text.find('[')]+' '+edited_text[edited_text.find(']')+1:len(edited_text)]\n",
    "            \n",
    "            Joey.append([season,episode, scene_count, order, \" \".join(edited_text.split()),  \" \".join(split.split())])\n",
    "            order=order+1\n",
    "            \n",
    "            \n",
    "        #its a rachel line    \n",
    "        elif clean_text.replace(' ','').find('rachel:')>-1:\n",
    "            edited_text=clean_text[7:len(clean_text)].replace(':',' ').strip()\n",
    "            split=''\n",
    "            \n",
    "            #find all comments and move them\n",
    "            while edited_text.find('[')>-1:\n",
    "                temp_string=edited_text[edited_text.find('['):edited_text.find(']')+1]\n",
    "                split=split+' '+temp_string\n",
    "                edited_text=edited_text[0:edited_text.find('[')]+' '+edited_text[edited_text.find(']')+1:len(edited_text)]\n",
    "            \n",
    "            Rachel.append([season,episode, scene_count, order, \" \".join(edited_text.split()),  \" \".join(split.split())])\n",
    "            order=order+1\n",
    "            \n",
    "        #its a chandler line    \n",
    "        elif clean_text.replace(' ','').find('chandler:')>-1:\n",
    "            edited_text=clean_text[9:len(clean_text)].replace(':',' ').strip()\n",
    "            split=''\n",
    "            \n",
    "            #find all comments and move them\n",
    "            while edited_text.find('[')>-1:\n",
    "                temp_string=edited_text[edited_text.find('['):edited_text.find(']')+1]\n",
    "                split=split+' '+temp_string\n",
    "                edited_text=edited_text[0:edited_text.find('[')]+' '+edited_text[edited_text.find(']')+1:len(edited_text)]\n",
    "                \n",
    "            \n",
    "            Chandler.append([season,episode, scene_count, order, \" \".join(edited_text.split()),  \" \".join(split.split())])\n",
    "            order=order+1\n",
    "            \n",
    "        #its a all line    \n",
    "        elif clean_text.replace(' ','').find('all:')>-1:\n",
    "            edited_text=clean_text[4:len(clean_text)].replace(':',' ').strip()\n",
    "            split=''\n",
    "            \n",
    "            #find all comments and move them\n",
    "            while edited_text.find('[')>-1:\n",
    "                temp_string=edited_text[edited_text.find('['):edited_text.find(']')+1]\n",
    "                split=split+' '+temp_string\n",
    "                edited_text=edited_text[0:edited_text.find('[')]+' '+edited_text[edited_text.find(']')+1:len(edited_text)]\n",
    "            \n",
    "            All.append([season,episode, scene_count, order, \" \".join(edited_text.split()),  \" \".join(split.split())])\n",
    "            order=order+1\n",
    "        \n",
    "            \n",
    "        #minor character\n",
    "        elif clean_text.find(':')>-1 and clean_text.replace(' ','').find('matthewperry')<0 and clean_text.replace(' ','').find('lisakudrow')<0:\n",
    "            name= clean_text[0:clean_text.find(':')].replace('mr.','mr').replace('mrs.','mrs')\n",
    "            edited_text=clean_text[len(name)+1:len(clean_text)]\n",
    "            split=''\n",
    "            \n",
    "            #find all comments and move them\n",
    "            while edited_text.find('[')>-1:\n",
    "                temp_string=edited_text[edited_text.find('['):edited_text.find(']')+1]\n",
    "                split=split+' '+temp_string\n",
    "                edited_text=edited_text[0:edited_text.find('[')]+' '+edited_text[edited_text.find(']')+1:len(edited_text)]\n",
    "                \n",
    "            minors.append([season, episode, scene_count,  order, name,\" \".join(edited_text.split()),  \" \".join(split.split())])\n",
    "            order=order+1\n",
    "        \n",
    "        \n",
    "            #do we have the name already in the list of all_char names?\n",
    "            isit=[n for n in all_char if n[0]==name]\n",
    "            if len(isit)==0:\n",
    "                all_char.append([name, False])\n",
    "                \n",
    "        else:\n",
    "            #not my problem?\n",
    "            unknown_junk.append(clean_text)\n",
    "            \n",
    "        j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'season': [m[0] for m in Monica],'episode': [m[1] for m in Monica],'scene': [m[2] for m in Monica],'quote_index': [m[3] for m in Monica],'line': [m[4] for m in Monica],'extra': [m[5] for m in Monica]}).to_csv('../data/Characters/Monica.csv', index=False)\n",
    "pd.DataFrame({'season': [m[0] for m in Ross],'episode': [m[1] for m in Ross],'scene': [m[2] for m in Ross],'quote_index': [m[3] for m in Ross],'line': [m[4] for m in Ross],'extra': [m[5] for m in Ross]}).to_csv('../data/Characters/Ross.csv', index=False)\n",
    "pd.DataFrame({'season': [m[0] for m in Phoebe],'episode': [m[1] for m in Phoebe],'scene': [m[2] for m in Phoebe],'quote_index': [m[3] for m in Phoebe],'line': [m[4] for m in Phoebe],'extra': [m[5] for m in Phoebe]}).to_csv('../data/Characters/Phoebe.csv', index=False)\n",
    "pd.DataFrame({'season': [m[0] for m in Joey],'episode': [m[1] for m in Joey],'scene': [m[2] for m in Joey],'quote_index': [m[3] for m in Joey],'line': [m[4] for m in Joey],'extra': [m[5] for m in Joey]}).to_csv('../data/Characters/Joey.csv', index=False)\n",
    "pd.DataFrame({'season': [m[0] for m in Rachel],'episode': [m[1] for m in Rachel],'scene': [m[2] for m in Rachel],'quote_index': [m[3] for m in Rachel],'line': [m[4] for m in Rachel],'extra': [m[5] for m in Rachel]}).to_csv('../data/Characters/Rachel.csv', index=False)\n",
    "pd.DataFrame({'season': [m[0] for m in Chandler],'episode': [m[1] for m in Chandler],'scene': [m[2] for m in Chandler],'quote_index': [m[3] for m in Chandler],'line': [m[4] for m in Chandler],'extra': [m[5] for m in Chandler]}).to_csv('../data/Characters/Chandler.csv', index=False)\n",
    "pd.DataFrame({'season': [m[0] for m in All],'episode': [m[1] for m in All],'scene': [m[2] for m in All],'quote_index': [m[3] for m in All],'line': [m[4] for m in All],'extra': [m[5] for m in All]}).to_csv('../data/Characters/All.csv', index=False)\n",
    "\n",
    "\n",
    "#For the Scene DataBase\n",
    "pd.DataFrame({'season': [m[0] for m in scenes],'episode': [m[1] for m in scenes],'scene': [m[2] for m in scenes],'location': [m[3] for m in scenes],\"extra_scene_info\": [m[4] for m in scenes]}).to_csv('../data/Characters/scenes.csv', index=False)\n",
    "\n",
    "#For the Minor Chatacters DataBasepd.DataFrame({'name':[m[0] for m in all_char],'main':[m[1] for m in all_char]})\n",
    "pd.DataFrame({'season': [m[0] for m in minors],'episode': [m[1] for m in minors],'scene': [m[2] for m in minors],'quote_index': [m[3] for m in minors],'character': [m[4] for m in minors],\"line\": [m[5] for m in minors],'extra': [m[6] for m in minors]}).to_csv('../data/Characters/minors.csv', index=False)\n",
    "\n",
    "#For the All Chatacters DataBase\n",
    "pd.DataFrame({'name':[m[0] for m in all_char],'main':[m[1] for m in all_char]}).to_csv('../data/Characters/all_char.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
